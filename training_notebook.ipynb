{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5f9aa2b-fca2-4712-bdfe-53e565730cac",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6df40772-d624-4727-ad6c-e2d46527b0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from helper import *\n",
    "from DataLoaderGeneric import *\n",
    "from BertController import *\n",
    "import json\n",
    "\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, DataCollatorWithPadding, Trainer, TrainerCallback, TrainingArguments\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f81bbe8-128a-460d-ab34-b6ffc2dcabf2",
   "metadata": {},
   "source": [
    "### C3 Training and saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53ae9768-e158-48c7-b3a8-f703888400dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "C:\\Users\\amit\\anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2336: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "data = DataLoaderGeneric(name='c3')\n",
    "bert = BertController(max_seq=512, num_labels=data.num_labels)\n",
    "data_dict = bert.extract_tokens_labels(texts=data.text, labels=data.labels)\n",
    "train_loader, validation_loader = data.train_test_split(data_dict,batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac5918c-9b11-40b9-b899-04abe75040ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert.train(train_loader, validation_loader, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264ac230-a637-4001-a306-3c5afe71c4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert.save_model('c3_256_3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d0bb97-7051-4da1-94eb-13235835805b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### FeedBack Training and saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9712ef-7e0b-4c4d-9421-3bd684d891c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataLoaderGeneric(name='feedback')\n",
    "bert = BertController(max_seq=512, num_labels=data.num_labels)\n",
    "data_dict = bert.extract_tokens_labels(texts=data.text, labels=data.labels)\n",
    "train_loader, validation_loader = data.train_test_split(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2953f9-35d6-4eeb-8a58-51962d2cfff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert.train(train_loader, validation_loader, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea912516-ad1b-487e-9ccf-960e57de9e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert.save_model('feedback_512_2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaee86c3-6a2f-4e42-b735-c21d6f69e8ba",
   "metadata": {},
   "source": [
    "### Loading of discourse dataset and generic function for pre-trained models loading and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "305155a7-f4d1-471c-90bf-6030fbba3347",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataLoaderGeneric(name='discourse')\n",
    "BASE_MODEL = \"bert-base-uncased\"\n",
    "id2label = {k:l for k, l in enumerate(labels_lst_org)}\n",
    "label2id = {l:k for k, l in enumerate(labels_lst_org)}\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL)\n",
    "data_dict = tokenizer(data.text, truncation=True, padding=\"max_length\", max_length=350)\n",
    "labels = data.labels\n",
    "data_dict['labels'] = labels\n",
    "train_dataloader, validation_dataloader, test_dataloader = data.train_test_split_discourse(tree_d=data.tree_depth, labels=labels, data_dict=data_dict,  batch_size=16, validation_ratio=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6de3a974-a35b-4bd0-a0eb-e877ada7a46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_multilabel_classification(preds, true_labels):\n",
    "    preds = preds.cpu().numpy()\n",
    "    true_labels = true_labels.cpu().numpy()\n",
    "    f1 = f1_score(true_labels, preds, average='weighted')\n",
    "    precision = precision_score(true_labels, preds, average='weighted')\n",
    "    recall = recall_score(true_labels, preds, average='weighted')\n",
    "    accuracy = accuracy_score(true_labels, preds)\n",
    "    print(f'F1-score: {f1}, Precision: {precision}, Recall: {recall}, Accuracy: {accuracy}')\n",
    "    \n",
    "    \n",
    "def run_pretrained_model(model_name, epochs=6):\n",
    "    model = BertForSequenceClassification.from_pretrained(model_name)\n",
    "    # Move the model to the GPU\n",
    "    # Change the output layer to produce 31 outputs\n",
    "    model.classifier = nn.Linear(model.classifier.in_features, 31)\n",
    "    # Use the BinaryCrossEntropyLoss for multilabel classification\n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "    loss_fn = loss_fn.to(device)\n",
    "    model = model.to(device)\n",
    "    # Set optimizer and scheduler\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=2e-5)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.9)\n",
    "\n",
    "    # Train the model\n",
    "    for epoch in range(1, epochs):\n",
    "        # Train one epoch\n",
    "        model.train()\n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "            input_ids, attention_masks, labels = batch\n",
    "            input_ids = input_ids.to(device)\n",
    "            attention_masks = attention_masks.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(input_ids, attention_masks)\n",
    "            loss = loss_fn(outputs[0], labels.float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        # Evaluate on validation set\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        preds = []\n",
    "        true_labels = []\n",
    "        for step, batch in enumerate(validation_dataloader):\n",
    "            input_ids, attention_masks, labels = batch\n",
    "            input_ids = input_ids.to(device)\n",
    "            attention_masks = attention_masks.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(input_ids, attention_masks)\n",
    "            val_loss += loss_fn(outputs[0], labels.float()).item()\n",
    "            preds.append(outputs[0].sigmoid() > 0.5)\n",
    "            true_labels.append(labels)\n",
    "        preds = torch.cat(preds, dim=0)\n",
    "        true_labels = torch.cat(true_labels, dim=0)\n",
    "        evaluate_multilabel_classification(preds, true_labels)\n",
    "    \n",
    "    # test\n",
    "    preds = []\n",
    "    true_labels = []\n",
    "    for step, batch in enumerate(test_dataloader):\n",
    "        input_ids, attention_masks, labels = batch\n",
    "        input_ids = input_ids.to(device)\n",
    "\n",
    "        attention_masks = attention_masks.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(input_ids, attention_masks)\n",
    "        val_loss += loss_fn(outputs[0], labels.float()).item()\n",
    "        preds.append(outputs[0].sigmoid() > 0.5)\n",
    "        true_labels.append(labels)\n",
    "    preds = torch.cat(preds, dim=0)\n",
    "    true_labels = torch.cat(true_labels, dim=0)\n",
    "    evaluate_multilabel_classification(preds, true_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54699413-d86b-45b2-a5e3-7515c402b001",
   "metadata": {},
   "source": [
    "### Discourse trained on feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9fa04c62-be3f-4692-902d-6fc34b936fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amit\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score: 0.26085151725049044, Precision: 0.21467244630867027, Recall: 0.3323432343234323, Accuracy: 0.14893617021276595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amit\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score: 0.2521940977120666, Precision: 0.23107784587982608, Recall: 0.27755775577557756, Accuracy: 0.13885778275475924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amit\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score: 0.2609809370507603, Precision: 0.2182932276550298, Recall: 0.3244224422442244, Accuracy: 0.14781634938409854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amit\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score: 0.2609809370507603, Precision: 0.2182932276550298, Recall: 0.3244224422442244, Accuracy: 0.14781634938409854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amit\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score: 0.2614502578342441, Precision: 0.2219024296046626, Recall: 0.31815181518151814, Accuracy: 0.14837625979843225\n",
      "F1-score: 0.23165023079168093, Precision: 0.19596862266167198, Recall: 0.28321805606115763, Accuracy: 0.12949640287769784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amit\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "run_pretrained_model('saved_models/feedback_512_2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca96ae86-cb9f-42cd-95d9-aa5869158e1b",
   "metadata": {},
   "source": [
    "### Discourse trained on C3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8be65b-452d-4676-8fbd-0ca9f4a1131e",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_pretrained_model('saved_models/c3_512_2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8fd948-14b1-4362-809f-c96195cae7a4",
   "metadata": {},
   "source": [
    "### Discourse trained on each label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f2928b7-311d-4f23-9ee4-a878a7567537",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = 'discourse'  # ['c3', 'feedback', 'discourse']\n",
    "data = DataLoaderGeneric(name=task_name)\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96e635b-ef0e-436f-80f3-41c9660639da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for i in tqdm(range(31)):\n",
    "    print(\"-\"*25, labels_lst_org[i], \"-\"*25)\n",
    "    labels = data.labels[:, i]\n",
    "    bert = BertController(256,2,'saved_models/c3_512_2')\n",
    "    data_dict = bert.tokenizer(data.text, truncation=True, padding=\"max_length\", max_length=256)\n",
    "    train_dataloader, validation_dataloader, test_dataloader = data.train_test_split_discourse(labels, data.tree_depth, data_dict,  batch_size=16, validation_ratio=0.2)\n",
    "    # model, optimizer = get_pretraind_bert('clean', 2)\n",
    "    # model.cuda()\n",
    "    bert.train(train_dataloader, validation_dataloader, epochs=3)\n",
    "    results[labels_lst_org[i]] = bert.metrics\n",
    "\n",
    "with open(\"results each label c3 transfer.txt\", 'a') as file:\n",
    "    for key in results.keys():\n",
    "        file.write(key+'\\n')\n",
    "        for key2 in results[key].keys():\n",
    "            file.write(str(results[key][key2])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960e0fe9-6096-4913-b618-c8a7e6d56ac2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
